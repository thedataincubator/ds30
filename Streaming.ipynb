{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Importing graphics related libraries\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns  # plots are prettier with Seaborn\n",
    "import onlineldavb\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "matplotlib.rcParams['savefig.dpi'] = 2 * matplotlib.rcParams['savefig.dpi']\n",
    "\n",
    "# importing useful libraries\n",
    "import simplejson\n",
    "import sys\n",
    "import requests\n",
    "from requests_oauthlib import OAuth1\n",
    "from collections import Counter\n",
    "import heapq\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from itertools import islice, chain\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup twitter authorization\n",
    "\n",
    "1. Need to authenticate (can you guess why?).  Creat a twitter account and get your API credentials on the [Twitter API page](http://apps.twitter.com/).\n",
    "1. Secrets not checked into source control (good practice)!\n",
    "1. Using python `stream` (like an infinite list!)\n",
    "1. Handle stream using python `generator`\n",
    "1. *Protip*: `simplejson` is faster than builtin `json`.\n",
    "1. *Protip*: `requests` is easier to use than builtin `urllib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"twitter_secrets.json.nogit\") as fh:\n",
    "    secrets = simplejson.loads(fh.read())\n",
    "\n",
    "auth = OAuth1(\n",
    "    secrets[\"api_key\"],\n",
    "    secrets[\"api_secret\"],\n",
    "    secrets[\"access_token\"],\n",
    "    secrets[\"access_token_secret\"]\n",
    ")\n",
    "\n",
    "US_BOUNDING_BOX = \"-125.00,24.94,-66.93,49.59\"\n",
    "def tweet_generator():\n",
    "    stream = requests.post('https://stream.twitter.com/1.1/statuses/filter.json',\n",
    "                         auth=auth,\n",
    "                         stream=True,\n",
    "                         data={\"locations\" : US_BOUNDING_BOX})\n",
    "    \n",
    "    for line in stream.iter_lines():\n",
    "        if not line:  # filter out keep-alive new lines\n",
    "            continue\n",
    "        tweet = simplejson.loads(line)\n",
    "        if 'text' in tweet:\n",
    "            yield tweet['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out twitter stream\n",
    "\n",
    "1. When handling streams, need to use `itertools` (`slice` -> `islice`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in islice(tweet_generator(), 100):\n",
    "    print tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Statistics\n",
    "\n",
    "1. Raw tweets less interesting than word counts\n",
    "1. Stop words necessary for NLP\n",
    "1. Leverage standard library functions and classes (e.g. `Counter`)\n",
    "1. Don't count iterations manually, use `enumerate`\n",
    "1. Don't print each iteration\n",
    "1. Difference between `\\r` vs. `\\n` and `print` vs. `sys.stdout.write`\n",
    "1. Capture `KeyboardInterrupt` makes output prettier\n",
    "1. `nlargest` should be computed using Heap Queue\n",
    "    ![Heap Queue](heapqueue.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DISPLAY_EVERY = 20\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "counter = Counter()\n",
    "\n",
    "def nlargest(n, word_scores):\n",
    "    return heapq.nlargest(n, word_scores, key=lambda x: x[1])\n",
    "\n",
    "try:\n",
    "    for k, tweet in enumerate(islice(tweet_generator(), 1000)):\n",
    "        for word in tweet.lower().split():\n",
    "            if word not in stop:\n",
    "                counter[word] += 1\n",
    "        if k % DISPLAY_EVERY == (DISPLAY_EVERY - 1):\n",
    "            sys.stdout.write(\"\\r\" + str(nlargest(10, counter.items())))\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    df = pd.DataFrame(nlargest(10, counter.items()), columns=['words', 'count'])\n",
    "    df.set_index('words').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize\n",
    "\n",
    "1. Lists of word counts not as useful\n",
    "1. Wordcloud: size of word ~ frequency (there's a library for that)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "try:\n",
    "    for k, tweet in enumerate(islice(tweet_generator(), 1000)):\n",
    "        for word in tweet.lower().split():\n",
    "            if word not in stop and 'http' not in word:\n",
    "                counter[word] += 1\n",
    "        if k % DISPLAY_EVERY == (DISPLAY_EVERY - 1):\n",
    "            wordcloud = WordCloud().fit_words(counter.items())\n",
    "            plt.axis(\"off\")\n",
    "            display.clear_output(wait=True)\n",
    "            plt.imshow(wordcloud)\n",
    "            display.display(plt.gcf())\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "1. Batch tweets (another generator)\n",
    "1. Online vs offline\n",
    "    1. streaming vs. big data\n",
    "1. Vectorization: convert word to index with a fixed vocabulary\n",
    "    1. Static vs. dynamic vocabulary\n",
    "    ![Vectorization](vectorization.png)\n",
    "1. Use sparse matrices when data is sparse\n",
    "1. We'll use KMeans to illustrate topic modelling.\n",
    "    1. Unsupervised learning.\n",
    "    1. Iteratively assign centers and update them:\n",
    "    ![KMeans](kmeans.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "CLUSTER_SIZE = 4\n",
    "\n",
    "kmeans = MiniBatchKMeans(n_clusters=CLUSTER_SIZE)\n",
    "\n",
    "def batch(iterable, size):\n",
    "    \"\"\" batch(\"ABCDEFG\", 3) -> ABC DEF G \"\"\"\n",
    "    sourceiter = iter(iterable)\n",
    "    while True:\n",
    "        batchiter = islice(sourceiter, size)\n",
    "        yield chain([batchiter.next()], batchiter)\n",
    "\n",
    "with open(\"dictnostops.txt\") as fh:\n",
    "    words = [line.strip() for line in fh.readlines()]\n",
    "    word_to_index = { word: k for k, word in enumerate(words) }\n",
    "\n",
    "def wordclouds(wordcounts):\n",
    "    wordclouds = [WordCloud().fit_words(counts) for counts in wordcounts]\n",
    "    fig, axes = plt.subplots(2,2)\n",
    "    display.clear_output(wait=True)\n",
    "    for k, (ax, wordcloud) in enumerate(zip(axes.flatten(), wordclouds)):\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(wordcloud)\n",
    "        ax.set_title(\"Topic %d\" % k)\n",
    "    display.display(fig)\n",
    "    fig.clear()\n",
    "\n",
    "try:\n",
    "    for tweets in batch(islice(tweet_generator(), 1000), BATCH_SIZE):\n",
    "        mat = sp.sparse.dok_matrix((BATCH_SIZE, len(words)))\n",
    "        for row, tweet in enumerate(tweets):\n",
    "            for word in tweet.lower().split():\n",
    "                if word in word_to_index:\n",
    "                    mat[row, word_to_index[word]] = 1.\n",
    "        kmeans.partial_fit(mat.tocsr())\n",
    "        wordcounts = [\n",
    "            nlargest(50, zip(words, kmeans.cluster_centers_[i]))\n",
    "            for i in xrange(kmeans.n_clusters)\n",
    "        ]\n",
    "        wordclouds(wordcounts)\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "1. Latent Dirichlet Alloction (LDA): A [Bayesian](https://en.wikipedia.org/wiki/Bayesian_probability) [Graphical Model](https://en.wikipedia.org/wiki/Graphical_model)\n",
    "    ![LDA](lda1.png)\n",
    "1. LDA is a topic model:\n",
    "    ![LDA](lda2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 4\n",
    "D = 1e9\n",
    "BATCH_SIZE = 20\n",
    "olda = onlineldavb.OnlineLDA(words, K, D, 1./K, 1./K, 1024., 0.7)\n",
    "\n",
    "try:\n",
    "    for tweets in batch(islice(tweet_generator(), 1000), BATCH_SIZE):\n",
    "        olda.update_lambda(list(tweets))\n",
    "        wordclouds(olda.topic_words(50))\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
